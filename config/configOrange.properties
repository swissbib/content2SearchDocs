# Properties for the transformation of CBS data to the orange (Basel Bern) swissbib index
#
# Authors: GÃ¼nther Hipler (ghi), Oliver Schihin (osc), Silvia Witzig (swi)
#
# History
# 2013.08.02 : ghi : Creation, revision, setup
# 2015.11.11 : osc : Cleanup, renaming
# 2015.11.11 : swi : Adaptions for deletes on orange and other orange specials
#
#****************General properties ***********************

# Flag and template to skip records
# if SKIPRECORDS is "false", template will not be used
SKIPRECORDS=true
XSLTTEMPLATESKIP=belongs.2.orange.repository.xsl

# Document weeding
SEARCHSERVER_WEEDING=http://sb-us6.swissbib.unibas.ch:8080/solr/sb-biblio
# I decided myself to put the absolute path into configuration file and not into the script used to start the whole process
PATH_WEEDING_DOCUMENTS_DELETE_ON_SERVER=/swissbib_index/solrDocumentProcessing/MarcToSolr/data/weedingDocumentsDeleteOnServer

# Template chain used to build the SearchEngine documents
# * sequence of templates used by XML2SearchDocsEngine
# * chaining of template simplifies extensions and adaptions to different use cases
XSLTTEMPLATES=swissbib.solr.step1.xsl##vufind.special.orange.xsl##swissbib.solr.vufind2.xsl

# Number of searcheEngine documents stored in one file
SOLRDOCSIZE=1000

# XSLT factory (default: net.sf.saxon.TransformerFactoryImpl)
TRANSFORMERIMPL=net.sf.saxon.TransformerFactoryImpl

# Name template for SOLR output files (default: solrout.xml)
BASENAME.FILE.SOLRDOCS=solrout.xml

# Logging of intermediate XSLT output file (absolute path with filename)
# * no logging if property is blank
# * an exception will be thrown if the indicated path doesn't exist
#INTERMEDIATE.RESULT.OUTPUT.DIR.FILE=/swissbib_index/solrDocumentProcessing/MarcToSolr/data/intermediate/intermediate.txt
INTERMEDIATE.RESULT.OUTPUT.DIR.FILE=

# Extension plugins called by the XSLT templates
#PLUGINS.TO.LOAD=org.swissbib.documentprocessing.plugins.FulltextContentEnrichment###org.swissbib.documentprocessing.plugins.RemoveDuplicates###org.swissbib.documentprocessing.plugins.GNDContentEnrichment###org.swissbib.documentprocessing.plugins.ViafContentEnrichment
PLUGINS.TO.LOAD=org.swissbib.documentprocessing.plugins.FulltextContentEnrichment###org.swissbib.documentprocessing.plugins.RemoveDuplicates###org.swissbib.documentprocessing.plugins.GNDContentEnrichment###org.swissbib.documentprocessing.plugins.DSV11ContentEnrichment###org.swissbib.documentprocessing.plugins.CreateSecondISBN###org.swissbib.documentprocessing.plugins.DeleteWeededDocuments
#please repeat each plugin which was loaded. Otherwise it isn't functional
#backgound: plugins has to be loaded in order to call them as extensions from XSLT templates - otherwise you will get errors in the templates
#often plugins need additional ressources (databases, indexes ....) to work in an expected way.
#if these resources are not available for test purposes you can remove the plugin from the configuration item PLUGINS.IN.PRODUCTIONMODE
#then it will be loaded but returns only an empty string
#do not load org.swissbib.documentprocessing.plugins.DeleteWeededDocuments for productive purposes poutside the Basel / Bern context unless you have the same special weeding requirements
PLUGINS.IN.PRODUCTIONMODE=org.swissbib.documentprocessing.plugins.FulltextContentEnrichment###org.swissbib.documentprocessing.plugins.RemoveDuplicates###org.swissbib.documentprocessing.plugins.GNDContentEnrichment###org.swissbib.documentprocessing.plugins.DSV11ContentEnrichment###org.swissbib.documentprocessing.plugins.CreateSecondISBN

#PLUGINS.IN.PRODUCTIONMODE=org.swissbib.documentprocessing.plugins.FulltextContentEnrichment###org.swissbib.documentprocessing.plugins.RemoveDuplicates###org.swissbib.documentprocessing.plugins.GNDContentEnrichment###org.swissbib.documentprocessing.plugins.DSV11ContentEnrichment###org.swissbib.documentprocessing.plugins.CreateSecondISBN###org.swissbib.documentprocessing.plugins.DeleteWeededDocuments

# Template used to pluck the complete holdings so they could be stored as a parameter used by the chained templates
collect.holdings.template=collect.holdings.orange.xsl

#the so called fullrecord of the searchDoc (mostly former bibliographic record) doesn't contain the complete holdings information (not needed for presentation in resultlist
#and would be punished with slow performance becuase the presentation component (VuFind) had to parse every complete record part of the resultlist
#(resultlists contain between 5 and 100 items). So most of the holdings information is weeded - and for the full view we use another structure (see collect.holdings.template)
#weedholdings.orange.xsl
weedholdings.template=weedholdings.orange.xsl

#
convert2composed=false

#configure a proxy server if necessary -> empty value: no proxy is used
#PROXYSERVER=proxy.unibas.ch:3128
PROXYSERVER=

#**************************  Definitions for FulltextContentEnrichment ************************************

#only documents matching these patterns are fetched and parsed for remote content
ALLOWED.DOCUMENTS=http://www\.ub\.unibas\.ch/tox/IDSLUZ/.*?/PDF###http://www\.ub\.unibas\.ch/tox/IDSBB/.*?/PDF###http://www\.ub\.unibas\.ch/tox/HBZ/.*?/OCR###http://d-nb\.info/.*?/04###http://aleph\.unisg\.ch/hsgscan/.*?\.pdf###http://opac\.nebis\.ch/objects/pdf/.*?\.pdf###http://biblio\.unizh\.ch/objects/pdf/.*?\.pdf###http://libraries\.admin\.ch/gw/toc/pdf/.*?\.pdf###https://www.edubs.ch/unterstuetzung/buecher/.*?\.pdf

#mit dieser property verhindere ich ein Fetchen von content bestimmter Adressen per HTTP (NEBIS)
#gleichzeitug wird aber vorhandener content aus der Datenbank (bereits frueher abgeholt) ausgelesen und verwendet
#da diese Adresse in Allowed.DOCUMENTS enthalten ist
HTTP.FETCH.NOT.ALLOWED=http://opac\.nebis\.ch/objects/pdf/.*?\.pdf###http://opac.nebis.ch/objects/pdf03/.*?\.pdf

#max number of characters considered by TIKA (application default: 10000)
MAXLENGTH.FETCHED.DOCUMENTS=30000

#in case want to use one single document for testing purposes (should not be used for production!)
TEST.PDF=
#[TRUE|FALSE or empty ] to switch on or off the remote fetching of documents

#a flag to activate the fulltext enrichement
REMOTEFETCHING=true

#valid content type
#course of action:
#1) open http connection for fulltext document
#2) look at the content type of the document
#3) if the content type of the document is part of this list, the content is going to be fetched and the http connection will be closed
#background: just at the beginning I encountered problems especially with application/pdf;charset=Binary related to Tika
#now I changed to the latest version (1.4 former version was 1.0 / 1.1) I didn't get any problems with only a few tests (e have to see)
ALLOWEDCONTENTTYPE=application/pdf###application/pdf;charset=UTF-8###application/pdf;charset=Binary



#access to database for cached remote content
JDBCDRIVER=com.mysql.jdbc.Driver
JDBCCONNECTION=jdbc:mysql://sb-db4.swissbib.unibas.ch:3306/remotecontent
#JDBCCONNECTION=jdbc:mysql://localhost:2000/remotecontent
#JDBCCONNECTION=jdbc:mysql://localhost:2000/remotecontenttest
user=[user]
passwd=[password]

#**************************  end Definitions for FulltextContentEnrichment *********************************************



#**************************  Definitions for GNDContentEnrichment and DSV11 ********************************************

#example https://portal.dnb.de/opac.htm?method=requestMarcXml&idn=4035964-5
#SOURCE.TO.FETCH.GND=https://portal.dnb.de/opac.htm?method=requestMarcXml&idn={0}
#SOURCE.TO.FETCH.GND=sb-db4.swissbib.unibas.ch
ID.PATTERN.TO.REPLACE=?##?
PATTERN.FOR.ID=^(\\(.*?\\))(.*)$
#datafield_subfield
TAGS.TO.USE=400_a###400_b###400_c###400_d###400_x###410_a###410_b###411_a###411_b###430_a###450_a###450_x###451_a###451_x
TAGS.TO.USE.FOR.MACS=750_a
#MONGO.CLIENT=localhost###29017
MONGO.CLIENT=sb-db6.swissbib.unibas.ch###29017
#use MONGO.AUTHENTICATION only in case authentication is activated on the database
MONGO.AUTHENTICATION=[authentication database]###[user]###[password]

#MONGO.DB=[contentDB]###[collection of the DB]###[search field -> field to store the gndid]###[response fields]###response fields for MACS (optional)
#What does it looks like in Mongo:
#{ "_id" : "(DNBGND)oai:d-nb.de/authorities/141390905", "status" : "new", "gndid" : "(DE-588)141390905",
#"dbid" : "141390905", "datum" : "2013-03-19", "record" :
#BinData(complete zipped gnd record), "gndfields" : { "400_a" : [ "Stollenz, Andreas", "Autopilot" ] } }
MONGO.DB=nativeSources###sourceDNBGND###gndid###gndfields###macsfields
MONGO.DB.DSV11=nativeSources###sourceDSV11

#**************************  end Definitions for GNDContentEnrichment and DSV11 ***************************************




#**************************  Definitions for VIAFContentEnrichment ****************************************************

#actually not used in production
#example https://portal.dnb.de/opac.htm?method=requestMarcXml&idn=4035964-5
VIAFINDEXBASE=http://sb-s1.swissbib.unibas.ch:8080/solr/viaf
#QUERYTEMPLATE=matchstring={0}
SEARCHFIELD=matchstring
VALUESFIELD=personname
IDFIELD=id

#**************************  end Definitions for GNDContentEnrichment *************************************************

